{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb437c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"OPENPI_DATA_HOME\"] = \"/home/lperez/.cache/openpi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fd4a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lperez/main/nh/openpi_subtask_generation/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import cv2\n",
    "from flax import nnx\n",
    "import time\n",
    "from openpi.models import model as _model\n",
    "import openpi.shared.nnx_utils as nnx_utils\n",
    "import jax.numpy as jnp\n",
    "from openpi.training.config import get_config\n",
    "from openpi.models.tokenizer import PaligemmaTokenizer\n",
    "from openpi.models.model import Observation\n",
    "from openpi.models.pi0 import make_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cff26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug line 0-1\n"
     ]
    }
   ],
   "source": [
    "PALIGEMMA_EOS_TOKEN = 1\n",
    "max_decoding_steps = 20\n",
    "temperature = 0.1\n",
    "\n",
    "### Step 1: Initialize model and load pretrained params\n",
    "config = get_config(\"right_pi05_20\")\n",
    "model_rng = jax.random.key(0)\n",
    "rng = jax.random.key(0)\n",
    "model = config.model.create(model_rng)\n",
    "\n",
    "# Load pretrained params\n",
    "print(f\"debug line 0-1\")\n",
    "graphdef, state = nnx.split(model)\n",
    "loader = config.weight_loader\n",
    "params = nnx.state(model)\n",
    "# Convert frozen params to bfloat16.\n",
    "params = nnx_utils.state_map(params, config.freeze_filter, lambda p: p.replace(p.value.astype(jnp.bfloat16)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908e7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_shape = params.to_pure_dict()\n",
    "loaded_params = loader.load(params_shape)\n",
    "state.replace_by_pure_dict(loaded_params)\n",
    "model = nnx.merge(graphdef, state)\n",
    "\n",
    "### Step 2: Construct an observation batch\n",
    "# load 3 images from tmp_test as uint8 format\n",
    "img_share_path = '/home/lperez/main/nh/openpi_subtask_generation/test'\n",
    "# img_name_list = ['to.png', 'lef.png', 'righ.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b62ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_name_list = ['leftImg.png', 'rightImg.png', 'faceImg.png']\n",
    "# img_name_list = ['cats/1.png', \"cats/2.png\", \"cats/3.png\"]\n",
    "# img_name_list = ['cup/1.png', \"cup/2.png\", \"cup/3.png\"]\n",
    "img_name_list = ['open/1.png', \"open/2.png\", \"open/3.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1a5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "for img_name in img_name_list:\n",
    "    img_path = os.path.join(img_share_path, img_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    img_list.append(img)\n",
    "# Convert images from [0, 255] to [-1, 1] range as expected by the model\n",
    "img_dict = {\n",
    "    \"base_0_rgb\": jnp.array(img_list[0][np.newaxis, :, :, :]).astype(jnp.float32) / 127.5 - 1.0,\n",
    "    \"left_wrist_0_rgb\": jnp.array(img_list[1][np.newaxis, :, :, :]).astype(jnp.float32) / 127.5 - 1.0,\n",
    "    \"right_wrist_0_rgb\": jnp.array(img_list[2][np.newaxis, :, :, :]).astype(jnp.float32) / 127.5 - 1.0,\n",
    "}\n",
    "\n",
    "# Pick up the flashcard on the table\n",
    "# Tokenize the prompt\n",
    "# high_level_prompt = 'Put the fruits on the basket'\n",
    "high_level_prompt = 'Put up the flashcard on the table'\n",
    "low_level_prompt = 'ASD'\n",
    "tokenizer = PaligemmaTokenizer(max_len=50)\n",
    "tokenized_prompt, tokenized_prompt_mask, token_ar_mask, token_loss_mask = tokenizer.tokenize_high_low_prompt(high_level_prompt, low_level_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d81aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a observation\n",
    "data = {\n",
    "    'image': img_dict,\n",
    "    'image_mask': {key: jnp.ones(1, dtype=jnp.bool) for key in img_dict.keys()},\n",
    "    'state': jnp.zeros((1, 32), dtype=jnp.float32),\n",
    "    # 'state': None,\n",
    "    'tokenized_prompt': jnp.stack([tokenized_prompt], axis=0),\n",
    "    'tokenized_prompt_mask': jnp.stack([tokenized_prompt_mask], axis=0),\n",
    "    'token_ar_mask': jnp.stack([token_ar_mask], axis=0),\n",
    "    'token_loss_mask': jnp.stack([token_loss_mask], axis=0),\n",
    "}\n",
    "observation = Observation.from_dict(data)\n",
    "rng = jax.random.key(42)\n",
    "observation = _model.preprocess_observation(rng, observation, train=False, image_keys=list(observation.images.keys()))\n",
    "\n",
    "# Set the low level task tokens to padding according to the loss mask (loss mask is the indication of low-level prompt)\n",
    "# We move it from inside model to outside because the inside func need to be jittable\n",
    "loss_mask = jnp.array(observation.token_loss_mask)\n",
    "new_tokenized_prompt = observation.tokenized_prompt.at[loss_mask].set(0)\n",
    "new_tokenized_prompt_mask = observation.tokenized_prompt_mask.at[loss_mask].set(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4424688",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_observation = _model.Observation(\n",
    "                    images=observation.images,\n",
    "                    image_masks=observation.image_masks,\n",
    "                    state=observation.state,\n",
    "                    tokenized_prompt=new_tokenized_prompt,\n",
    "                    tokenized_prompt_mask=new_tokenized_prompt_mask,\n",
    "                    token_ar_mask=observation.token_ar_mask,\n",
    "                    token_loss_mask=observation.token_loss_mask,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050e0521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a observation\n",
    "data = {\n",
    "    'image': img_dict,\n",
    "    'image_mask': {key: jnp.ones(1, dtype=jnp.bool) for key in img_dict.keys()},\n",
    "    'state': jnp.zeros((1, 32), dtype=jnp.float32),\n",
    "    # 'state': None,\n",
    "    'tokenized_prompt': jnp.stack([tokenized_prompt], axis=0),\n",
    "    'tokenized_prompt_mask': jnp.stack([tokenized_prompt_mask], axis=0),\n",
    "    'token_ar_mask': jnp.stack([token_ar_mask], axis=0),\n",
    "    'token_loss_mask': jnp.stack([token_loss_mask], axis=0),\n",
    "}\n",
    "observation = Observation.from_dict(data)\n",
    "rng = jax.random.key(42)\n",
    "observation = _model.preprocess_observation(rng, observation, train=False, image_keys=list(observation.images.keys()))\n",
    "\n",
    "# Set the low level task tokens to padding according to the loss mask (loss mask is the indication of low-level prompt)\n",
    "# We move it from inside model to outside because the inside func need to be jittable\n",
    "loss_mask = jnp.array(observation.token_loss_mask)\n",
    "new_tokenized_prompt = observation.tokenized_prompt.at[loss_mask].set(0)\n",
    "new_tokenized_prompt_mask = observation.tokenized_prompt_mask.at[loss_mask].set(False)\n",
    "new_observation = _model.Observation(\n",
    "                    images=observation.images,\n",
    "                    image_masks=observation.image_masks,\n",
    "                    state=observation.state,\n",
    "                    tokenized_prompt=new_tokenized_prompt,\n",
    "                    tokenized_prompt_mask=new_tokenized_prompt_mask,\n",
    "                    token_ar_mask=observation.token_ar_mask,\n",
    "                    token_loss_mask=observation.token_loss_mask,\n",
    "                    )\n",
    "observation = _model.preprocess_observation(None, new_observation, train=False, image_keys=list(observation.images.keys()))\n",
    "observation = jax.tree.map(jax.device_put, observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d08ca71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[     2,   7071, 235292,   2507,    908,    573,  12995,   5306,\n",
       "           611,    573,   3037, 235265,   4284,   8277, 235292, 235248,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation.tokenized_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa4f02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation.tokenized_prompt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f224f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpi.models.pi05 import left_to_right_align\n",
    "from openpi.models.pi05 import put_along_last_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d21d82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = observation.tokenized_prompt.shape[0]\n",
    "prefix_token_embeddings, prefix_mask, prefix_ar_mask = model.embed_prefix(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff1764c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_attn_mask = make_attn_mask(prefix_mask, prefix_ar_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e4d223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        [ True,  True,  True, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]], dtype=bool)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e5ad06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # left to right align all input token sequences\n",
    "        prefix_token_embeddings, prefix_mask, prefix_attn_mask = left_to_right_align(\n",
    "            prefix_token_embeddings, prefix_mask, prefix_attn_mask\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f25c148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        prefill_size = prefix_token_embeddings.shape[1]\n",
    "        prefill_len = jnp.sum(prefix_mask, axis=-1)\n",
    "        prefix_start = prefill_size - prefill_len\n",
    "\n",
    "        prefix_attn_mask = jnp.pad(prefix_attn_mask, ((0, 0), (0, 0), (0, max_decoding_steps)))\n",
    "        prefix_positions = jnp.cumsum(prefix_mask, axis=-1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95db8651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False], dtype=bool)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_attn_mask[0][818]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058683d",
   "metadata": {},
   "source": [
    "FIRST CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "056e6f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(prefix_out, _), kv_cache = model.PaliGemma.llm(\n",
    "            [prefix_token_embeddings, None], mask=prefix_attn_mask, positions=prefix_positions, adarms_cond=[None, None]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65e6d48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "        last_token_embedding = prefix_out[:, -1:]\n",
    "        last_logits = model.PaliGemma.llm(last_token_embedding, method=\"deembed\")\n",
    "        last_logits = jax.nn.log_softmax(last_logits, axis=-1)\n",
    "        output_tokens = jnp.zeros((batch_size, max_decoding_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54892459",
   "metadata": {},
   "outputs": [],
   "source": [
    "        def step(carry):\n",
    "            rng, last_logit, output_tokens, cache, _, step = carry\n",
    "\n",
    "            # Sample token from last logit\n",
    "            # Split RNG for this step\n",
    "            rng, rng_step = jax.random.split(rng)\n",
    "            token = jax.lax.cond(\n",
    "                temperature > 0.0,\n",
    "                lambda _: jax.random.categorical(rng_step, last_logit / temperature, axis=-1),\n",
    "                lambda _: jnp.argmax(last_logit, axis=-1),\n",
    "                operand=None,\n",
    "            )\n",
    "            output_tokens = put_along_last_axis(output_tokens, jnp.broadcast_to(step, (token.shape[0], 1)), token)\n",
    "\n",
    "            # Check for early stopping --> stop if all batch elements have EOS token\n",
    "            ### TODO: erase extra decoded token due to mismatch\n",
    "            has_eos = jnp.any(token == PALIGEMMA_EOS_TOKEN, axis=-1)\n",
    "            all_eos = jnp.all(has_eos)\n",
    "\n",
    "            # Decode one step\n",
    "            token_embedding =  model.PaliGemma.llm(token, method=\"embed\")\n",
    "            positions = prefill_len[:, None] + step\n",
    "            jax.debug.print(\"positions: {s}\", s=positions)\n",
    "            mask = jnp.logical_and(\n",
    "                jnp.arange(prefill_size + max_decoding_steps)[None, None, :] >= prefix_start[:, None, None],\n",
    "                jnp.arange(prefill_size + max_decoding_steps)[None, None, :]\n",
    "                < (jnp.broadcast_to(prefill_size + step + 1, (prefix_start.shape[0], 1, 1))),\n",
    "            )\n",
    "            #jax.debug.print(\"step: {s}\", s=step)\n",
    "            jax.debug.print(\"runningmask.shape . {m}\", m=mask.astype(jnp.int32).shape)\n",
    "            jax.debug.print(\"runningmask. . {m}\", m=mask.astype(jnp.int32))\n",
    "            (prefix_out, _), kv_cache = model.PaliGemma.llm(\n",
    "                [token_embedding, None], mask=mask, positions=positions, adarms_cond=[None, None], kv_cache=cache\n",
    "            )\n",
    "            last_token_embedding = prefix_out[:, -1:]\n",
    "            last_logits = model.PaliGemma.llm(last_token_embedding, method=\"deembed\")\n",
    "            last_logits = jax.nn.log_softmax(last_logits, axis=-1)\n",
    "\n",
    "            #jax.debug.print(\"STEP: {s}\", s=step)\n",
    "            #jax.debug.print(\"MASK: {m}\", m=mask.astype(jnp.int32))\n",
    "            #jax.debug.print(\"POSITIONS: {p}\", p=positions.astype(jnp.int32))\n",
    "\n",
    "            return rng, last_logits, output_tokens, kv_cache, all_eos, step + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91002049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions: [[784]]\n",
      "runningmask.shape . (Array(1, dtype=int32), Array(1, dtype=int32), Array(838, dtype=int32))\n",
      "runningmask. . [[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]]\n",
      "positions: [[785]]\n",
      "runningmask.shape . (Array(1, dtype=int32), Array(1, dtype=int32), Array(838, dtype=int32))\n",
      "runningmask. . [[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]]\n",
      "positions: [[786]]\n",
      "runningmask.shape . (Array(1, dtype=int32), Array(1, dtype=int32), Array(838, dtype=int32))\n",
      "runningmask. . [[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]]\n",
      "positions: [[787]]\n",
      "runningmask.shape . (Array(1, dtype=int32), Array(1, dtype=int32), Array(838, dtype=int32))\n",
      "runningmask. . [[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]]\n",
      "positions: [[788]]\n",
      "runningmask.shape . (Array(1, dtype=int32), Array(1, dtype=int32), Array(838, dtype=int32))\n",
      "runningmask. . [[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "        def cond(carry):\n",
    "            _, _, _, _, all_eos, step = carry\n",
    "            return (~all_eos) & (step < max_decoding_steps)\n",
    "\n",
    "        # Use lax.while_loop so we can jit the full decoding loop.\n",
    "        _, _, output_tokens, kv_cache, _, _ = jax.lax.while_loop(\n",
    "            cond, step, (rng, last_logits, output_tokens, kv_cache, False, 0)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55a2684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pick up white tape'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.detokenize(np.array(output_tokens, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a78b44c",
   "metadata": {},
   "source": [
    "Prompt, describe image, open: \"The image features a person's legs, a foot, and a foot. The person is wearing\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa8e1e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
